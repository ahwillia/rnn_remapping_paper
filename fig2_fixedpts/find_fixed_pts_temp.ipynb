{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "sys.path.append(\"../utils/\")\n",
    "\n",
    "from model_utils import load_model_params, sample_rnn_data, format_rnn_data\n",
    "\n",
    "from scipy.special import softmax\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.ndimage import maximum_filter1d\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from time import time\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = f\"../data/saved_models/1d_2map/\"\n",
    "\n",
    "# get the model IDs for all saved models\n",
    "model_IDs = os.listdir(data_folder)\n",
    "\n",
    "# select example model\n",
    "ex_id = 0\n",
    "model_ID = model_IDs[ex_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = f\"../data/saved_models/1d_2map/{model_ID}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPERPARAMETERS ###\n",
    "model, task_params, _ = load_model_params(data_folder, model_ID)\n",
    "\n",
    "train_params = {\n",
    "    \"batch_size\": 124,\n",
    "    \"num_iters\": 5000,\n",
    "    \"init_lr\": 0.1,\n",
    "    \"lr_step_size\": 50,\n",
    "    \"lr_step_gamma\": 0.99,\n",
    "    \"momentum\": 0.0,\n",
    "    \"grad_clip_norm\": 2.0,\n",
    "    \"updates_per_difficulty_increase\": 100,\n",
    "    \"difficulty_increase\": 1,\n",
    "    \"random_sample\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_pts(X, num_pts=1000):\n",
    "    '''\n",
    "    Choose initialization points randomly from throughout the activity space.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    X : ndarray, shape (n_obs, n_units)\n",
    "        RNN unit activity at each observation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    init_states : ndarray, shape (num_pts, n_units)\n",
    "        points in activity space from which to initialize\n",
    "        the fixed point finder\n",
    "    '''\n",
    "    # find the top 3 PCs for the neural activity space\n",
    "    pca = PCA(n_components=3).fit(X)\n",
    "    pcs = pca.transform(X)\n",
    "\n",
    "    # define the corners\n",
    "    pc_max = np.max(pcs, axis=0)\n",
    "    pc_min = np.min(pcs, axis=0)\n",
    "    pc_corners = np.stack((pc_min, pc_max), axis=0)\n",
    "\n",
    "    # randomly sample initial states\n",
    "    init_pcs = torch.zeros([num_pts, 3])\n",
    "    for x in range(3):\n",
    "        x_min = np.min(pc_corners[:, x])\n",
    "        x_max = np.max(pc_corners[:, x])    \n",
    "        init_pcs[:, x] = (x_min - x_max) * torch.rand(num_pts) + x_max\n",
    "        \n",
    "    # transform back to full D\n",
    "    init_states = pca.inverse_transform(init_pcs)\n",
    "\n",
    "    return init_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUTS ###\n",
    "# get sample rnn data\n",
    "inputs, outputs, targets = sample_rnn_data(data_folder, model_ID)\n",
    "X, map_targ, pos_targ = format_rnn_data(outputs[\"hidden_states\"],\\\n",
    "                                                targets[\"map_targets\"],\\\n",
    "                                                targets[\"pos_targets\"])\n",
    "\n",
    "# initial state guesses (num_points, hidden_size)\n",
    "init_states = initial_pts(X)\n",
    "init_states = torch.from_numpy(init_states)\n",
    "prev_states = torch.nn.Parameter(init_states)\n",
    "\n",
    "# set the velocity and context inputs to zero\n",
    "num_pts = init_states.shape[0]\n",
    "inp_vel = torch.zeros(num_pts, 1)\n",
    "inp_remaps = torch.zeros(num_pts, task_params[\"num_maps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 5000/5000 [00:26<00:00, 190.53it/s]\n"
     ]
    }
   ],
   "source": [
    "### SGD ###\n",
    "# for stochastic gradient descent\n",
    "optimizer = SGD(\n",
    "    [prev_states],\n",
    "    lr=train_params[\"init_lr\"],\n",
    "    momentum=train_params[\"momentum\"]\n",
    ")\n",
    "\n",
    "# to update the learning rate\n",
    "scheduler = StepLR(\n",
    "    optimizer,\n",
    "    step_size=train_params[\"lr_step_size\"],\n",
    "    gamma=train_params[\"lr_step_gamma\"]\n",
    ")\n",
    "\n",
    "\n",
    "vel_losses = []\n",
    "\n",
    "for itercount in trange(train_params[\"num_iters\"]):\n",
    "\n",
    "    # Prepare optimizer.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass.\n",
    "    next_states = model.one_step(prev_states, inp_vel, inp_remaps)\n",
    "\n",
    "    # Evaluate loss - how close is the velocity to 0?\n",
    "    vel_loss = torch.sum((prev_states - next_states)**2)\n",
    "    vel_losses.append(vel_loss.item())\n",
    "\n",
    "    # Compute gradient.\n",
    "    vel_loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if itercount == (train_params[\"num_iters\"] - 1):\n",
    "        next_states, pos_outputs = model.one_step(prev_states, \\\n",
    "                                                    inp_vel, \\\n",
    "                                                    inp_remaps, \\\n",
    "                                                    return_pos=True)\n",
    "\n",
    "### SAVE OUTPUTS ###\n",
    "np.save(outdir + \"vel_losses.npy\", vel_losses)\n",
    "fixed_pts_np = next_states.detach().numpy()\n",
    "np.save(outdir + \"states_fixed_pt.npy\", fixed_pts_np)\n",
    "pos_outputs_np = pos_outputs.detach().numpy()\n",
    "np.save(outdir + \"pos_fixed_pt.npy\", pos_outputs_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
